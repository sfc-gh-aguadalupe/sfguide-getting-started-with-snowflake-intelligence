{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting Model with Snowpark ML\n",
    "\n",
    "This notebook trains an XGBoost regression model to predict sales amounts based on:\n",
    "- Date features (month, day of week)\n",
    "- Region\n",
    "- Product category\n",
    "\n",
    "The model is registered in Snowflake's Model Registry and can be called as a tool from the Snowflake Intelligence Agent."
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark and ML imports\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, month, dayofweek, year\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.preprocessing import OrdinalEncoder\n",
    "from snowflake.ml.registry import Registry\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get active Snowpark session (when running in Snowsight)\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# IMPORTANT: Update these values based on your lab path\n",
    "# For Manual path (si_*): DATABASE = 'SI_DB', MODEL_NAME = 'si_sales_forecast'\n",
    "# For Cortex Code path (coco_*): DATABASE = 'COCO_DB', MODEL_NAME = 'coco_sales_forecast'\n",
    "\n",
    "DATABASE = 'SI_DB'  # Change to 'COCO_DB' for Cortex Code path\n",
    "SCHEMA = 'RETAIL'\n",
    "MODEL_NAME = 'si_sales_forecast'  # Change to 'coco_sales_forecast' for Cortex Code path\n",
    "\n",
    "# Set database and schema context - REQUIRED for temp table operations\n",
    "session.use_database(DATABASE)\n",
    "session.use_schema(SCHEMA)\n",
    "\n",
    "print(f\"Using database: {DATABASE}\")\n",
    "print(f\"Using schema: {SCHEMA}\")\n",
    "print(f\"Model will be registered as: {MODEL_NAME}\")"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sales data with product info\n",
    "sales_df = session.table(f\"{DATABASE}.{SCHEMA}.SALES\")\n",
    "products_df = session.table(f\"{DATABASE}.{SCHEMA}.PRODUCTS\")\n",
    "\n",
    "# Join sales with products to get category\n",
    "df = sales_df.join(\n",
    "    products_df,\n",
    "    sales_df[\"PRODUCT_ID\"] == products_df[\"PRODUCT_ID\"],\n",
    "    \"left\"\n",
    ").select(\n",
    "    sales_df[\"DATE\"],\n",
    "    sales_df[\"REGION\"],\n",
    "    products_df[\"CATEGORY\"],\n",
    "    sales_df[\"UNITS_SOLD\"],\n",
    "    sales_df[\"SALES_AMOUNT\"]\n",
    ")\n",
    "\n",
    "print(f\"Total records: {df.count()}\")\n",
    "df.show(5)"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: extract date features\n",
    "df_features = df.with_column(\"MONTH\", month(col(\"DATE\"))) \\\n",
    "               .with_column(\"DAY_OF_WEEK\", dayofweek(col(\"DATE\"))) \\\n",
    "               .with_column(\"YEAR\", year(col(\"DATE\")))\n",
    "\n",
    "# Select features for modeling\n",
    "df_model = df_features.select(\n",
    "    \"REGION\",\n",
    "    \"CATEGORY\", \n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"YEAR\",\n",
    "    \"UNITS_SOLD\",\n",
    "    \"SALES_AMOUNT\"\n",
    ").dropna()\n",
    "\n",
    "print(f\"Records after feature engineering: {df_model.count()}\")\n",
    "df_model.show(5)"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encode Categorical Features"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (REGION, CATEGORY)\n",
    "categorical_cols = [\"REGION\", \"CATEGORY\"]\n",
    "output_cols = [\"REGION_ENCODED\", \"CATEGORY_ENCODED\"]\n",
    "\n",
    "encoder = OrdinalEncoder(\n",
    "    input_cols=categorical_cols,\n",
    "    output_cols=output_cols\n",
    ")\n",
    "\n",
    "encoder.fit(df_model)\n",
    "df_encoded = encoder.transform(df_model)\n",
    "\n",
    "df_encoded.show(5)"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target\n",
    "feature_cols = [\"REGION_ENCODED\", \"CATEGORY_ENCODED\", \"MONTH\", \"DAY_OF_WEEK\", \"YEAR\", \"UNITS_SOLD\"]\n",
    "target_col = \"SALES_AMOUNT\"\n",
    "\n",
    "# Split data 80/20\n",
    "train_df, test_df = df_encoded.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training records: {train_df.count()}\")\n",
    "print(f\"Test records: {test_df.count()}\")"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost Model"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train XGBoost regressor\n",
    "model = XGBRegressor(\n",
    "    input_cols=feature_cols,\n",
    "    label_cols=[target_col],\n",
    "    output_cols=[\"PREDICTED_SALES\"],\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost model...\")\n",
    "model.fit(train_df)\n",
    "print(\"Training complete!\")"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions_df = model.predict(test_df)\n",
    "\n",
    "# Convert to pandas for evaluation\n",
    "results_pd = predictions_df.select(target_col, \"PREDICTED_SALES\").to_pandas()\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = results_pd[target_col]\n",
    "y_pred = results_pd[\"PREDICTED_SALES\"]\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"RMSE: ${rmse:,.2f}\")\n",
    "print(f\"MAE:  ${mae:,.2f}\")\n",
    "print(f\"R2:   {r2:.3f}\")"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "predictions_df.select(\n",
    "    \"REGION\", \"CATEGORY\", \"MONTH\", target_col, \"PREDICTED_SALES\"\n",
    ").show(10)"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Register Model in Snowflake Model Registry"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize registry\n",
    "registry = Registry(session=session, database_name=DATABASE, schema_name=SCHEMA)\n",
    "\n",
    "# Log the model to registry\n",
    "model_version = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    version_name=\"v1\",\n",
    "    model=model,\n",
    "    comment=f\"XGBoost sales forecasting model. RMSE: ${rmse:,.2f}, R2: {r2:.3f}\"\n",
    ")\n",
    "\n",
    "print(f\"Model registered: {MODEL_NAME} v1\")\n",
    "print(f\"Full path: {DATABASE}.{SCHEMA}.{MODEL_NAME}\")"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models in registry\n",
    "print(\"\\nModels in registry:\")\n",
    "for m in registry.models():\n",
    "    print(f\"  - {m.name}\")"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Model Inference via SQL"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with sample data\n",
    "# Note: After registration, you can call the model via SQL like:\n",
    "# SELECT model_name!PREDICT(...) FROM ...\n",
    "\n",
    "test_query = f\"\"\"\n",
    "WITH sample_data AS (\n",
    "    SELECT \n",
    "        1 AS REGION_ENCODED,  -- e.g., 'West'\n",
    "        2 AS CATEGORY_ENCODED, -- e.g., 'Electronics'\n",
    "        7 AS MONTH,\n",
    "        3 AS DAY_OF_WEEK,\n",
    "        2025 AS YEAR,\n",
    "        50 AS UNITS_SOLD\n",
    ")\n",
    "SELECT * FROM sample_data\n",
    "\"\"\"\n",
    "\n",
    "sample_df = session.sql(test_query)\n",
    "prediction = model.predict(sample_df)\n",
    "prediction.show()"
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Call Model via SQL\n",
    "\n",
    "The registered model can be called directly using SQL. This is the recommended approach for using ML models in Snowflake."
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the registered model directly via SQL\n",
    "# The model exposes a PREDICT method that can be called using: MODEL_NAME!PREDICT(...)\n",
    "\n",
    "inference_sql = f\"\"\"\n",
    "WITH sample_input AS (\n",
    "    SELECT \n",
    "        1.0::FLOAT AS REGION_ENCODED,\n",
    "        2.0::FLOAT AS CATEGORY_ENCODED,\n",
    "        8.0::FLOAT AS MONTH,\n",
    "        3.0::FLOAT AS DAY_OF_WEEK,\n",
    "        2025.0::FLOAT AS YEAR,\n",
    "        100.0::FLOAT AS UNITS_SOLD\n",
    ")\n",
    "SELECT {DATABASE}.{SCHEMA}.{MODEL_NAME}!PREDICT(\n",
    "    REGION_ENCODED, CATEGORY_ENCODED, MONTH, DAY_OF_WEEK, YEAR, UNITS_SOLD\n",
    "):PREDICTED_SALES::FLOAT AS predicted_sales\n",
    "FROM sample_input\n",
    "\"\"\"\n",
    "\n",
    "result = session.sql(inference_sql).collect()\n",
    "print(f\"Predicted sales (via SQL): ${result[0]['PREDICTED_SALES']:,.2f}\")"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how to use the model on actual data\n",
    "batch_inference_sql = f\"\"\"\n",
    "SELECT \n",
    "    REGION,\n",
    "    CATEGORY,\n",
    "    MONTH,\n",
    "    UNITS_SOLD,\n",
    "    SALES_AMOUNT AS ACTUAL_SALES,\n",
    "    {DATABASE}.{SCHEMA}.{MODEL_NAME}!PREDICT(\n",
    "        REGION_ENCODED, CATEGORY_ENCODED, MONTH, DAY_OF_WEEK, YEAR, UNITS_SOLD\n",
    "    ):PREDICTED_SALES::FLOAT AS PREDICTED_SALES\n",
    "FROM (\n",
    "    SELECT \n",
    "        s.REGION,\n",
    "        p.CATEGORY,\n",
    "        MONTH(s.DATE) AS MONTH,\n",
    "        DAYOFWEEK(s.DATE) AS DAY_OF_WEEK,\n",
    "        YEAR(s.DATE) AS YEAR,\n",
    "        s.UNITS_SOLD,\n",
    "        s.SALES_AMOUNT,\n",
    "        -- Encoding (simplified)\n",
    "        CASE s.REGION WHEN 'East' THEN 0 WHEN 'West' THEN 1 WHEN 'North' THEN 2 ELSE 3 END AS REGION_ENCODED,\n",
    "        CASE p.CATEGORY WHEN 'Electronics' THEN 0 WHEN 'Fitness Wear' THEN 1 WHEN 'Home Appliances' THEN 2 WHEN 'Smart Home' THEN 3 ELSE 4 END AS CATEGORY_ENCODED\n",
    "    FROM {DATABASE}.{SCHEMA}.SALES s\n",
    "    JOIN {DATABASE}.{SCHEMA}.PRODUCTS p ON s.PRODUCT_ID = p.PRODUCT_ID\n",
    "    LIMIT 10\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Batch predictions on sample data:\")\n",
    "session.sql(batch_inference_sql).show()"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "The model is now registered in the Snowflake Model Registry and can be called via SQL.\n",
    "\n",
    "**How to use the model:**\n",
    "```sql\n",
    "SELECT SI_DB.RETAIL.SI_SALES_FORECAST!PREDICT(\n",
    "    region_encoded, category_encoded, month, day_of_week, year, units_sold\n",
    "):PREDICTED_SALES::FLOAT AS prediction\n",
    "FROM your_table\n",
    "```\n",
    "\n",
    "**Next Steps:**\n",
    "1. Go to Snowflake Intelligence\n",
    "2. Edit your agent\n",
    "3. Add a new tool of type \\\"Cortex Analyst\\\" pointing to the semantic model\n",
    "4. The agent can now query sales data and the model can be used for predictions"
   ],
   "id": "cell-24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}